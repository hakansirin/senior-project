{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import json as js\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randgen(pr, N=1): \n",
    "    L = len(pr)\n",
    "    return int(np.random.choice(range(L), size=N, replace=True, p=pr))\n",
    "\n",
    "def log_sum_exp(l, axis=0):\n",
    "    l_star = np.max(l, axis=axis, keepdims=True)\n",
    "    idx = np.where(l_star == float('-inf'))\n",
    "    l_star[idx] = -1e32\n",
    "    return l_star + np.log(np.sum(np.exp(l - l_star),axis=axis,keepdims=True)) \n",
    "\n",
    "def normalize_exp(log_P, axis=None):\n",
    "    a = np.max(log_P, keepdims=True, axis=axis)\n",
    "    P = normalize(np.exp(log_P - a), axis=axis)\n",
    "    return P\n",
    "\n",
    "def normalize(A, axis=None):\n",
    "    Z = np.sum(A, axis=axis,keepdims=True)\n",
    "    idx = np.where(Z == 0)\n",
    "    Z[idx] = 1\n",
    "    return A/Z\n",
    "\n",
    "def normpdf(x, mean, sd):\n",
    "        var = float(sd)**2\n",
    "        pi = 3.1415926\n",
    "        denom = (2*pi*var)**.5\n",
    "        num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "        return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HMM(object):\n",
    "    def __init__(self, pi, A, B_avg, B_sd):\n",
    "        # p(x_0)\n",
    "        self.pi = pi\n",
    "        # p(x_k|x_{k-1})\n",
    "        self.A = A\n",
    "        # p(y_k|x_{k})\n",
    "        self.B_avg = B_avg\n",
    "        self.B_sd = B_sd\n",
    "        \n",
    "        \n",
    "        # Number of possible latent states at each time\n",
    "        self.S = pi.shape[0]\n",
    "        \n",
    "        self.logB_avg = np.log(self.B_avg)\n",
    "        self.logB_sd = np.log(self.B_sd)\n",
    "\n",
    "        self.logA = np.log(self.A)\n",
    "        self.logpi = np.log(self.pi)\n",
    "    \n",
    "    def set_param(self, pi=None, A=None, B=None):\n",
    "        if pi is not None:\n",
    "            self.pi = pi\n",
    "            self.logpi = np.log(self.pi)\n",
    "\n",
    "        if A is not None:\n",
    "            self.A = A\n",
    "            self.logA = np.log(self.A)\n",
    "\n",
    "        if B_avg is not None:\n",
    "            self.B_avg = B_avg\n",
    "            self.logB_avg = np.log(self.B_avg)\n",
    "            \n",
    "        if B_sd is not None:\n",
    "            self.B_sd = B_sd\n",
    "            self.logB_sd = np.log(self.B_sd)\n",
    "\n",
    "    @classmethod\n",
    "    def from_random_parameters(cls, S=3):\n",
    "        A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "        B_avg = (3*np.random.rand(1,S)).reshape(S)\n",
    "        B_sd = (np.random.rand(1,S)).reshape(S)\n",
    "        pi = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "        return cls(pi, A, B_avg, B_sd)\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"Prior:\\n\" + str(self.pi) + \"\\nA:\\n\" + str(self.A) + \"\\nB_avd:\\n\" + str(self.B_avg)+ \"\\nB_sd:\\n\" + str(self.B_sd)\n",
    "        return s\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = self.__str__()\n",
    "        return s\n",
    "    \n",
    "    def log_prob_list(self, y):\n",
    "        l = []\n",
    "        for i in range(self.S):\n",
    "            l.append(normpdf(y,self.B_avg[i],self.B_sd[i]))\n",
    "        return np.log(l)\n",
    "\n",
    "    def predict(self, lp):\n",
    "        lstar = np.max(lp)\n",
    "        return lstar + np.log(np.dot(self.A,np.exp(lp-lstar)))\n",
    "\n",
    "    def postdict(self, lp):\n",
    "        lstar = np.max(lp)\n",
    "        return lstar + np.log(np.dot(np.exp(lp-lstar), self.A))\n",
    "\n",
    "    def predict_maxm(self, lp):\n",
    "        return np.max(self.logA + lp, axis=1)\n",
    "\n",
    "    def postdict_maxm(self, lp):\n",
    "        return np.max(self.logA.T + lp, axis=1)\n",
    "\n",
    "    def update(self, y, lp):\n",
    "        return self.log_prob_list(y) + lp if not np.isnan(y) else lp\n",
    "    \n",
    "    \n",
    "    def generate_sequence(self, T=10):\n",
    "    # T: Number of steps\n",
    "\n",
    "        x = np.zeros(T, int)\n",
    "        y = np.zeros(T, float)\n",
    "\n",
    "        for t in range(T):\n",
    "            if t==0:\n",
    "                x[t] = randgen(self.pi)\n",
    "            else:\n",
    "                x[t] = randgen(self.A[:,x[t-1]])  \n",
    "            \n",
    "            y[t] =self.B_sd[x[t]] * np.random.randn() + self.B_avg[x[t]]\n",
    "    \n",
    "        return y, x\n",
    "\n",
    "    def forward(self, y, maxm=False):\n",
    "        T = len(y)\n",
    "        \n",
    "        # Forward Pass\n",
    "\n",
    "        # Python indices start from zero so\n",
    "        # log \\alpha_{k|k} will be in log_alpha[:,k-1]\n",
    "        # log \\alpha_{k|k-1} will be in log_alpha_pred[:,k-1]\n",
    "        log_alpha  = np.zeros((self.S, T))\n",
    "        log_alpha_pred = np.zeros((self.S, T))\n",
    "        for k in range(T):\n",
    "            if k==0:\n",
    "                log_alpha_pred[:,0] = self.logpi\n",
    "            else:\n",
    "                if maxm:\n",
    "                    log_alpha_pred[:,k] = self.predict_maxm(log_alpha[:,k-1])\n",
    "                else:\n",
    "                    log_alpha_pred[:,k] = self.predict(log_alpha[:,k-1])\n",
    "\n",
    "                \n",
    "            log_alpha[:,k] = self.update(y[k], log_alpha_pred[:,k])\n",
    "            \n",
    "        return log_alpha, log_alpha_pred\n",
    "            \n",
    "    def backward(self, y, maxm=False):\n",
    "        # Backward Pass\n",
    "        T = len(y)\n",
    "        log_beta  = np.zeros((self.S, T))\n",
    "        log_beta_post = np.zeros((self.S, T))\n",
    "\n",
    "        for k in range(T-1,-1,-1):\n",
    "            if k==T-1:\n",
    "                log_beta_post[:,k] = np.zeros(self.S)\n",
    "            else:\n",
    "                if maxm: \n",
    "                    log_beta_post[:,k] = self.postdict_maxm(log_beta[:,k+1])                    \n",
    "                else:\n",
    "                    log_beta_post[:,k] = self.postdict(log_beta[:,k+1])\n",
    "\n",
    "            log_beta[:,k] = self.update(y[k], log_beta_post[:,k])\n",
    "\n",
    "        return log_beta, log_beta_post\n",
    "        \n",
    "    def forward_backward_smoother(self, y):\n",
    "        log_alpha, log_alpha_pred = self.forward(y)\n",
    "        log_beta, log_beta_post = self.backward(y)\n",
    "        \n",
    "        log_gamma = log_alpha + log_beta_post\n",
    "        return log_gamma\n",
    "\n",
    "    def viterbi(self, y):\n",
    "        T = len(y)\n",
    "        \n",
    "        # Forward Pass\n",
    "        log_alpha  = np.zeros((self.S, T))\n",
    "        for k in range(T):\n",
    "            if k==0:\n",
    "                log_alpha_pred = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred = self.predict(log_alpha[:,k-1])\n",
    "                \n",
    "            log_alpha[:,k] = self.update(y[k], log_alpha_pred)\n",
    "\n",
    "        xs = list()\n",
    "        w = np.argmax(log_alpha[:,-1])\n",
    "        xs.insert(0, w)                \n",
    "        for k in range(T-2,-1,-1):\n",
    "            w = np.argmax(log_alpha[:,k] + self.logA[w,:])\n",
    "            xs.insert(0, w)                \n",
    "            \n",
    "        return xs\n",
    "            \n",
    "    def get_ll(self,y):\n",
    "        return log_sum_exp(self.forward_backward_smoother(y))[0][0]\n",
    "\n",
    "    \n",
    "    def viterbi_maxsum(self, y):\n",
    "        '''Vanilla implementation of Viterbi decoding via max-sum'''\n",
    "        '''This algorithm may fail to find the MAP trajectory as it breaks ties arbitrarily'''\n",
    "        log_alpha, log_alpha_pred = self.forward(y, maxm=True)\n",
    "        log_beta, log_beta_post = self.backward(y, maxm=True)\n",
    "        \n",
    "        log_delta = log_alpha + log_beta_post\n",
    "        return np.argmax(log_delta, axis=0)\n",
    "\n",
    "    \n",
    "    def correction_smoother(self, y):\n",
    "        # Correction Smoother\n",
    "        log_alpha, log_alpha_pred = self.forward(y)\n",
    "        T = len(y)\n",
    "        \n",
    "        ll = self.get_ll(y)\n",
    "    \n",
    "        # For numerical stability, we calculate everything in the log domain\n",
    "        log_gamma_corr = np.zeros_like(log_alpha)\n",
    "        log_gamma_corr[:,T-1] = log_alpha[:,T-1]\n",
    "\n",
    "        C2 = np.zeros((self.S, self.S))\n",
    "        C3_m = np.zeros((1, self.S))\n",
    "        C3_sd = np.zeros((1, self.S))\n",
    "\n",
    "        for k in range(T-2,-1,-1):\n",
    "            log_old_pairwise_marginal = log_alpha[:,k].reshape(1,self.S) + self.logA \n",
    "            log_old_marginal = self.predict(log_alpha[:,k])\n",
    "            log_new_pairwise_marginal = log_old_pairwise_marginal + log_gamma_corr[:,k+1].reshape(self.S,1) - log_old_marginal.reshape(self.S,1)\n",
    "            log_gamma_corr[:,k] = log_sum_exp(log_new_pairwise_marginal, axis=0).reshape(self.S)\n",
    "            C2 += normalize_exp(log_new_pairwise_marginal)\n",
    "            #print('run : '+ str(k))\n",
    "            #print(log_new_pairwise_marginal)\n",
    "            \n",
    "        C1 = normalize_exp(log_gamma_corr[:,0])\n",
    "        \n",
    "        \n",
    "        delta = normalize_exp(self.forward_backward_smoother(y), axis=0)\n",
    "        C3_m = np.dot(delta,y)/np.sum(delta,axis=1)\n",
    "        \n",
    "        y_broadcast = np.zeros((T, hmm.S))\n",
    "        y = y.reshape(T,1)\n",
    "        y_broadcast += y\n",
    "        y_sd = np.power(y_broadcast - hmm.B_avg,2)\n",
    "        C3_sd = np.power(np.sum(delta * y_sd.T, axis=1)/np.sum(delta,axis=1),1/2)\n",
    "\n",
    "        return log_gamma_corr, C1, C2, C3_m, C3_sd, ll\n",
    "    \n",
    "\n",
    "    def train_EM(self, y, EPOCH=10):\n",
    "        \n",
    "        LL = np.zeros(EPOCH)\n",
    "        for e in range(EPOCH):\n",
    "            log_gamma_corr, C1, C2, C3_avg, C3_sd, ll = self.correction_smoother(y)\n",
    "            LL[e] = ll\n",
    "            p = normalize(C1 + 0.1, axis=0).reshape(self.S)\n",
    "            A = normalize(C2, axis=0)\n",
    "            B_avg = C3_avg\n",
    "            B_sd = C3_sd\n",
    "\n",
    "            self.__init__(p, A, B_avg, B_sd)\n",
    "            \n",
    "        return LL\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states of generated stream\n",
      "[1 2 3 1 3 1 2 1 1 3 3 1 1 3 1 2 3 1 3 2 1 2 1 3 1 0 3 3 3 1 1 2 1 2 2 1 3\n",
      " 1 2 1 3 1 2 3 1 3 3 1 3 1 3 3 1 2 1 3 1 0 0 0 1 2 2 1 1 3 1 3 1 0 3 1 2 1\n",
      " 2 3 1 2 1 3 2 1 0 0 0 3 2 2 2 1 3 2 1 1 3 1 3 1 1 2 3 1 3 1 3 3 1 3 1 2 1\n",
      " 3 1 2 3 1 3 3 1 2 1 3 1 1 2 1 3 1 1 2 3 3 1 3 1 2 3 1 3 1 2 1 2 3 1 1 2 1\n",
      " 3 1 2 1 3 1 1 2 1 3 1 3 1 0 2 1 2 2 3 1 1 1 3 3 1 3 1 3 3 2 3 1 1 2 2 3 2\n",
      " 1 1 2 1 1 1 3 1 1 2 1 2 1 2 3 3 1 2 1 2 1 3 1 2 2 1 3 2 1 2 1 3 1 3 2 1 3\n",
      " 3 1 3 2 1 2 1 2 2 1 2 1 3 3 1 1 1 3 1 1 3 1 2 1 2 1 1 2 3 3 1 2 1 3 3 3 3\n",
      " 1 2 3 3 3 0 3 3 3 1 3 3 1 3 1 3 3 1 2 3 1 3 3 2 1 2 2 3 1 3 1 2 2 1 3 2 1\n",
      " 1 3 1 2]\n",
      "predictions using the HMM model\n",
      "[3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1 1 1 1 0 1 3 1 1 1 1 1 1 3 1 3\n",
      " 1 1 1 0 1 1 1 1 1 3 1 3 1 1 3 3 1 1 1 0 0 0 0 3 1 2 1 1 1 1 3 1 0 0 3 1 1\n",
      " 1 1 1 1 1 3 1 1 0 0 0 3 1 3 1 1 3 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 3 1 1 3 1 3 3 1 1 3 1 1 3 1 1 3 1 1 1 3 1 1 3 1 2 1 3 1 2 1 3 1 1 1\n",
      " 1 1 1 1 1 1 1 3 1 3 1 3 1 0 3 1 1 1 1 1 3 1 3 1 1 3 1 1 3 1 3 1 1 1 1 3 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 3 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1\n",
      " 2 1 3 1 1 1 2 1 0 3 1 1 3 1 1 1 1 3 1 1 1 1 3 1 3 1 3 1 1 0 1 1 1 1 1 3 1\n",
      " 2 1 3 1 1 0 3 1 3 1 2 1 1 1 1 3 1 1 1 1 1 1 1 1 1 3 1 1 1 1 0 2 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "accuracy of state predictions using only emission parameters\n",
      "0.44\n",
      "accuracy of state predictions using HMM parameters\n",
      "0.5233333333333333\n",
      "accuracy of state predictions after the training using the same HMM\n",
      "0.49\n",
      "[[0.5034798  0.02127026 0.01317306 0.02427434]\n",
      " [0.03965739 0.1708696  0.59575059 0.66641011]\n",
      " [0.12499358 0.40597259 0.21984053 0.09613674]\n",
      " [0.33186923 0.40188755 0.17123582 0.2131788 ]]\n",
      "accuracy of state predictions using the random model\n",
      "0.30333333333333334\n",
      "accuracy of state predictions using the trained model\n",
      "0.30666666666666664\n",
      "[[0.25156155 0.34713528 0.64571497 0.38101518]\n",
      " [0.67753042 0.37293326 0.03172884 0.10202798]\n",
      " [0.06281151 0.06723755 0.1105702  0.03174316]\n",
      " [0.00809652 0.21269391 0.211986   0.48521369]]\n"
     ]
    }
   ],
   "source": [
    "STATE_COUNT = 4\n",
    "hmm = HMM.from_random_parameters(S=STATE_COUNT)\n",
    "\n",
    "y,x = hmm.generate_sequence(300)\n",
    "#print(hm)\n",
    "#print(y)\n",
    "#print(x)\n",
    "log_alpha, log_alpha_pred = hmm.forward(y)\n",
    "log_gamma = hmm.forward_backward_smoother(y)\n",
    "x_pred = (np.argmax(log_gamma,axis=0))\n",
    "\n",
    "print('states of generated stream')\n",
    "print(x)\n",
    "print('predictions using the HMM model')\n",
    "print(x_pred)\n",
    "\n",
    "\n",
    "\n",
    "x_only_y = []\n",
    "for elem in y:\n",
    "    x_only_y.append(hmm.log_prob_list(elem))\n",
    "\n",
    "x_only_y = (np.argmax(x_only_y,axis=1))\n",
    "\n",
    "print('accuracy of state predictions using only emission parameters')\n",
    "print((x==x_only_y).sum()/len(x))\n",
    "\n",
    "print('accuracy of state predictions using HMM parameters')\n",
    "print((x==x_pred).sum()/len(x))\n",
    "\n",
    "hmm.train_EM(y)\n",
    "log_gamma = hmm.forward_backward_smoother(y)\n",
    "x_pred = (np.argmax(log_gamma,axis=0))\n",
    "print('accuracy of state predictions after the training using the same HMM')\n",
    "#print(x_pred)\n",
    "print((x==x_pred).sum()/len(x))\n",
    "print(hmm.A)\n",
    "\n",
    "\n",
    "hmm = HMM.from_random_parameters(S=STATE_COUNT)\n",
    "\n",
    "print('accuracy of state predictions using the random model')\n",
    "log_gamma = hmm.forward_backward_smoother(y)\n",
    "x_pred = (np.argmax(log_gamma,axis=0))\n",
    "print((x==x_pred).sum()/len(x))\n",
    "\n",
    "hmm.train_EM(y)\n",
    "log_gamma = hmm.forward_backward_smoother(y)\n",
    "x_pred = (np.argmax(log_gamma,axis=0))\n",
    "print('accuracy of state predictions using the trained model')\n",
    "#print(x_pred)\n",
    "print((x==x_pred).sum()/len(x))\n",
    "print(hmm.A)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Matrix\n",
      "[[0.25068859 0.13239537 0.79776762]\n",
      " [0.46485194 0.1121735  0.17372109]\n",
      " [0.28445947 0.75543113 0.02851129]]\n",
      "Next A\n",
      "[[0.09101917 0.00959018 0.68520716]\n",
      " [0.77988849 0.0249252  0.29896259]\n",
      " [0.12909234 0.96548462 0.01583026]]\n",
      "\n",
      "[1.14866456 2.22265288 2.27283375]\n",
      "[0.78003757 2.52034435 2.27779658]\n",
      "-10.08812839893194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM.from_random_parameters()\n",
    "y,x = hmm.generate_sequence(10)\n",
    "\n",
    "log_gamma_corr, C1, C2, C3_avg, C3_sd, ll = hmm.correction_smoother(y)\n",
    "\n",
    "print('A Matrix')\n",
    "print(hmm.A)\n",
    "print('Next A')\n",
    "print(normalize(C2, axis=0))\n",
    "print()\n",
    "print(hmm.B_avg)\n",
    "print(C3_avg)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original A\n",
      "[[0.04994272 0.00330775 0.01476125 0.11279035 0.13527381 0.00352991\n",
      "  0.01195555 0.28474921]\n",
      " [0.48230243 0.20015207 0.11098424 0.33907692 0.16638825 0.03912203\n",
      "  0.01930254 0.27217327]\n",
      " [0.01462947 0.03164034 0.18224758 0.1315031  0.13917767 0.00064066\n",
      "  0.02730968 0.00314088]\n",
      " [0.00365346 0.00189341 0.30707881 0.01063751 0.02760255 0.01062425\n",
      "  0.08228535 0.06768435]\n",
      " [0.09068665 0.03240293 0.01172918 0.05822387 0.24233524 0.17268258\n",
      "  0.09941892 0.18314912]\n",
      " [0.29397978 0.09049057 0.06459119 0.26516616 0.00560968 0.0071592\n",
      "  0.39128746 0.00776633]\n",
      " [0.02064784 0.03217072 0.00214508 0.0036199  0.04980359 0.50317002\n",
      "  0.31403273 0.04434051]\n",
      " [0.04415765 0.60794221 0.30646268 0.07898218 0.23380921 0.26307136\n",
      "  0.05440776 0.13699633]]\n",
      "original B_avg\n",
      "[1.9639668  2.54190721 0.71642684 1.00055949 1.91641586 0.18027844\n",
      " 2.5966422  1.40118812]\n",
      "original B_std\n",
      "[0.73210697 0.33609706 0.94919839 0.3798595  0.07652361 0.03130195\n",
      " 0.91657108 0.55310409]\n",
      "original ll for the first series\n",
      "-127.1821298762244\n",
      "original ll for the second series\n",
      "-94.98237873410244\n",
      "original ll for the second series for random hmm\n",
      "-151.56833999233558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n",
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in log\n",
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original ll for the second series for trained hmm\n",
      "-129.15417001213734\n",
      "learned A\n",
      "[[7.96028848e-002 1.70109077e-038 2.83756127e-030 2.26657548e-001\n",
      "  1.27718118e-008 2.78375919e-029 4.35299399e-001 4.61250870e-036]\n",
      " [1.35572807e-021 0.00000000e+000 1.72038782e-149 1.10039183e-120\n",
      "  0.00000000e+000 6.89191801e-054 1.07689509e-001 2.49382992e-001]\n",
      " [3.25149100e-031 2.00116175e-001 0.00000000e+000 1.64552316e-001\n",
      "  7.64694327e-291 3.78210964e-029 7.09271511e-002 1.72368888e-132]\n",
      " [4.75379776e-002 2.92092690e-046 1.43551974e-007 6.85062209e-034\n",
      "  6.84347457e-001 4.00798430e-048 1.57521771e-016 4.46648897e-162]\n",
      " [7.43140089e-103 3.77121717e-236 6.07708228e-001 0.00000000e+000\n",
      "  0.00000000e+000 6.20478316e-001 1.79580944e-080 2.49700828e-001]\n",
      " [9.62139898e-002 4.82364149e-192 7.43104943e-056 2.78718233e-001\n",
      "  2.09508726e-001 2.08613016e-001 3.65460942e-002 2.96262446e-059]\n",
      " [7.76645148e-001 5.62040948e-102 3.92291628e-001 3.30071903e-001\n",
      "  1.06143805e-001 1.70908668e-001 3.49537847e-001 5.00916180e-001]\n",
      " [4.75623417e-033 7.99883825e-001 8.87611858e-295 2.80158989e-131\n",
      "  3.34571465e-011 4.24538850e-113 2.09836543e-017 0.00000000e+000]]\n",
      "learned B_avg\n",
      "[ 1.46623179 -0.52968298  0.71376453  1.49186444  0.17369995  3.31667967\n",
      "  2.41739514  1.45780851]\n",
      "learned B_std\n",
      "[0.5452524  0.41415872 0.06848902 0.30711759 0.03126615 0.50514341\n",
      " 0.40461445 0.1227221 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHSpJREFUeJzt3XuYVPWd5/H3t6obGgQEFeTStKC2F/Buq7Cbi6sYycwkXhKjxl2TfYxMYrJjZiYX87g7m+wz2Vxmn2TiJOPIqkmMJpqoqBtRNrhJjMmgXEShaRwaEGgu0oACTTfd1VXf/aNOQ9FUdXX36erqPufzep56us7vdy7fw6HPt8/v/M75mbsjIiLxlih3ACIiUn5KBiIiomQgIiJKBiIigpKBiIigZCAiIigZiIgISgYiIoKSgYiIABXlDqC3TjnlFJ8xY0a5wxARGTZWrly5x90n9mbeYZMMZsyYwYoVK8odhojIsGFmW3o7r5qJREREyUBERJQMREQEJQMREUHJQEREUDIQERGUDEREhGH0nIGIyHDj7rR3ZuhIZ+jozGS/d3Z9Tx8pa+9M0546+v1w6ujPymSCz115RsljVTIQkUHl7qQzTsYh4x58IJ3x4+rSma7p3J8c+d6ZU9+ZPlqWyXTVZY7Mk0ofne5Me/AzdzpDKp0tS6UzpDJd3z07nfO9ozO7XNf3rpP9kemgLJUOP8b8pLEjlQykPNIZ53AqfeSvlFSnB/+xM3SmnVQmQzr4BUpnsr9Ex/7SQtqP/8V2zz0BZE8Knmfa6ZrOfvdj6vKUdy/LmebI9NE6us0PPa+HI9vqtkyh7Rwpz053zcsxcfewHfLFlLOurn+jzLHr4Lh1ZpfPBCvpWlfGu81zzL+5H1lX5sjy2W11xZTpPn/OMTyy7m7TuSf9ocoMKhMJKpJGZTJBZfCzImlUJhKMqEgcnU4mGFWZZGxVBSOS2bqun9llE4ysPFo2suLoPNnyJCMqElRVdpUlGVmRoCr4mfu9Ijk4rflKBjG0p6WdZZv2snLLu+zaf5jmg+00t7TTcriTlvZO2jsz5Q6xT8zAADMLfoKRLcydzp0Pst/JXTbPejhmuWPXQ+66LP927MiG8sdodnQ91m09ufvGMctl5090388EGInjY8lZNnHMdrqVd1tfomsbOXXZeY/OD0YycXS9iYQdmS+ZOLpc93m61n3MdzOSXdOJbFky+J79CclEgqRl15dMJI6styKRyNabUZG0I/NVJI2KRHa9yYRRkUxQmcius+vEn0xkT+7JRNdRjadQycDMbgK+DpwLXO7uK3LqvgbcAaSBv3L3JUH5fOAHQBJ40N2/HSYG6Z3Wjk6eWL6NJ5ZvY/2ugwCMqkwydXwVk8ZWcWH1eMZWVTBmZAWjRiQZ1fUXSmWSEckElRXZX6KKnL+Usr9cFvwyHv1Fzv7idZ1M7OhJwYJfagPsaH3XiSd7Mjv2xNTTSbZrnSISXtgrg7XAjcADuYVmNgu4BZgNTAWWmtlZQfWPgGuAJmC5mT3n7utCxiEF7G9N8eArm3jkX7ewvy3FxTXj+fK1Z/PvzjiZ86edOGiXoCIytIVKBu7eAHn/OrsOeNzd24HNZtYIXB7UNbr7pmC5x4N5lQwGmLvz1KrtfGtxA/taO7jm3FP5yw+ezqWnnVTu0ERkCCrVPYNpwLKc6aagDGBbt/IrShRDbG3d28qXfvUGr729j4trxvPIHZcze+qJ5Q5LRIawosnAzJYCk/NU3evuzw58SMdsewGwAKCmpqaUm4qMLXsPcfMDy2jt6OQ7Hzufmy6dTiLmN8ZEpLiiycDd5/VjvduB6TnT1UEZPZTn2/ZCYCFAXV3dEO6UNjRs3dvKrQuX0d6Z5vEFc5k1dVy5QxKRYaJUdw+fA24xs5FmNhOoBV4DlgO1ZjbTzEaQvcn8XIliiJVt+1q59X8vozWV5tHPXKFEICJ9ErZr6Q3APwETgefNbLW7X+vu9Wb2S7I3hjuBz7t7OljmC8ASsl1LH3b3+lB7ILR3pvnsoys5eDjFz++co/sDItJnYXsTLQIWFaj7JvDNPOWLgcVhtivH+tbi9dTvOMCDt9dx3jQlAhHpO3UyH+ZeXLuLn/zpbe5430zmzTq13OGIyDClZDCMbdvXyleefIMLqk/kq/PPKXc4IjKMKRkMUy3tnfzlz1biDj+89RJGVOhQikj/6UV1w1AqneFzj67krXcO8vCnL6Pm5NHlDklEhjn9OTnMuDtfe3oNf9iwh2/deD4fPGtiuUMSkQhQMhhG3J1vv7ieJ1c28cV5tXyibnrxhUREekHNRMNEKp3hnqfW8NSqJm67ooa7r64td0giEiFKBsNAS3snn3t0JX/YsIcvzqvl7qtr9R5/ERlQSgZDXOPuFj7/2Coam1v47scu4BOXqWlIRAaeksEQ9vSqJv7rM2upqkzyk/98Ge+v1c1iESkNJYMhaH9riv/x63U8taqJy2ecxH23XszkE6vKHZaIRJiSwRDzwpqd/N1z9ew71MF/uepM7r66VkNTikjJKRkMEW/vOcQ3Fzfwm3XvMGvKOH786cv00jkRGTRKBmW271AH9720gUeXbWFERYKvzj+Hz7x/JpW6GhCRQaRkUCYHDqd4+JXNPPSHzRzq6OTmy2r462tqmTRW9wZEZPApGQyyto40P/7TZh74/Sb2t6W4dvap/O2HzuasU8eWOzQRiTElg0GSyTjPrN7OPyx5i537D3PVOZP4m2vO0n0BERkSQjVMm9lNZlZvZhkzq8spP9nMfmtmLWb2w27LXGpma8ys0czusxg8SruxuYXr//mP/M0v32Di2JE8sWAOD+sGsYgMIWGvDNYCNwIPdCs/DPw34Lzgk+t+4E7gVbLDX84HXggZx5C1eM1OvvyrNxhRkeD7N1/IdRdOI5GIfP4TkWEm7BjIDcBx78lx90PAK2Z2Zm65mU0Bxrn7smD6EeB6IpgM0hnnfy5u4KFXNnPR9PH8822XMHX8qHKHJSKS12DfM5gGNOVMNwVlkfPdJet56JXNfGruadz757M0EpmIDGlFk4GZLQUm56m6192fHfiQjtn2AmABQE1NTSk3NaB+/eYOHvj9Jm67ooZvXNe9lUxEZOgpmgzcfd4Abm87UJ0zXR2UFdr2QmAhQF1dnQ9gHCWzftcBvvyrN7n0tAn894/MLnc4IiK9MqhtF+6+EzhgZnOCXkS3AyW9uhhMBw6nWPDISsZWVXD/bRqkXkSGj7BdS28wsyZgLvC8mS3JqXsb+B7waTNrMrNZQdVdwINAI7CRCN08/uXybWzd18oPP3kJk8bpSWIRGT7C9iZaBCwqUDejQPkKju9uGglPrdrOhdUncvnMk8odiohIn6gdY4Cs23GAhp0HuPGS6uIzi4gMMUoGA+TpVU1UJo2PXji13KGIiPSZksEA6ExneGb1Dq46ZxITThhR7nBERPpMyWAA/GHDHva0tKuJSESGLSWDAfDUqiYmjK7kP5w9qdyhiIj0i5JBSPvbUvzfde/w0Qun6rkCERm2dPYKacnaXXR0ZtREJCLDmpJBSC/W76J6wiguqNbYBCIyfCkZhHDwcIpXNuxh/uzJx73GW0RkOFEyCOF3bzXTkc5w7Xn5XuoqIjJ8KBmE8GL9Lk4ZM5JLaiaUOxQRkVCUDPrpcCrN79bv5ppZp5LUMJYiMswpGfTTHxv3cKgjzXw1EYlIBCgZ9NOLa3cxtqqCuaefXO5QRERCUzLoh850hqUN73D1OZP0oJmIRILOZP3w2tv7eLc1xbWz1UQkItGgZNAPr2zYQ0XC+MBZE8sdiojIgAg77OVNZlZvZhkzq8spv8bMVprZmuDnVTl1lwbljWZ2nw3Dp7VWbX2XWVPHccLIUAPFiYgMGWGvDNYCNwIvdyvfA3zE3c8HPgX8LKfufuBOoDb4zA8Zw6DqTGd4Y9t+PVsgIpESdgzkBuC4VzG4++s5k/XAKDMbCZwEjHP3ZcFyjwDXAy+EiWMwrd91kLZUmotrxpc7FBGRATMY9ww+Bqxy93ZgGtCUU9cUlOVlZgvMbIWZrWhubi5xmL3z+tZ3AXRlICKRUvTKwMyWAvm6zdzr7s8WWXY28B3gQ/0Jzt0XAgsB6urqvD/rGGirtr7HxLEjqZ4wqtyhiIgMmKLJwN3n9WfFZlYNLAJud/eNQfF2IPfF/9VB2bCxauu7XFIzXm8pFZFIKUkzkZmNB54H7nH3P3aVu/tO4ICZzQl6Ed0O9Hh1MZTsaWlny95WLlYTkYhETNiupTeYWRMwF3jezJYEVV8AzgT+zsxWB5+uAYLvAh4EGoGNDKObx6u3vgfofoGIRE/Y3kSLyDYFdS//e+DvCyyzAjgvzHbLZdXWd6lImEY1E5HI0RPIfdD1sFlVZbLcoYiIDCglg17Sw2YiEmVKBr2kh81EJMqUDHpJD5uJSJQpGfTSup0HGT+6Ug+biUgkKRn00sbdLdROGqOHzUQkkpQMeqmxuYUzJo4pdxgiIiWhZNAL+w51sO9QB2dOUjIQkWhSMuiFjc0tAJyhZCAiEaVk0AuNu7PJ4Ew1E4lIRCkZ9ELj7haqKhNMG6+eRCISTUoGvdC4u4XTTxlDIqGeRCISTUoGvbCxuUU3j0Uk0pQMimjrSLP9vTYlAxGJNCWDIjY2t+COkoGIRJqSQRFd3UqVDEQkysKOdHaTmdWbWcbM6nLKL88Z4ewNM7shp26+mb1lZo1mdk+Y7Q+Gxt0tJAxOO3l0uUMRESmZUCOdAWuBG4EH8pTXuXunmU0B3jCz/wM48CPgGqAJWG5mz7n7upBxlMzG5hZOO/kERlZoQBsRia6ww142AMe9vM3dW3Mmq8gmAYDLgUZ33xQs9zhwHTBkk0Hjbr2TSESir2T3DMzsCjOrB9YAn3X3TmAasC1ntqagbEjqTGfYvOeQ7heISOQVvTIws6XA5DxV97r7s4WWc/dXgdlmdi7wUzN7oa/BmdkCYAFATU1NXxcPbeu+VlJp54yJJwz6tkVEBlPRZODu88JswN0bzKwFOA/YDkzPqa4OygotuxBYCFBXV+eF5iuVI+8k0pWBiERcSZqJzGymmVUE308DzgHeBpYDtUH9COAW4LlSxDAQNjYfAvS2UhGJvrBdS28wsyZgLvC8mS0Jqt5HtgfRamARcJe77wnuG3wBWAI0AL909/owMZTShncOMnlcFeOqKssdiohISYXtTbSI7Mm+e/nPgJ8VWGYxsDjMdgdL/Y4DzJo6rtxhiIiUnJ5ALuBwKk1jcwuzpigZiEj0KRkU8G/vHCSdcWbrykBEYkDJoID6HQcA1EwkIrGgZFDAuh0HGDuygukT9E4iEYk+JYMC6nfs59wp4zS6mYjEgpJBHumMs37XQTURiUhsKBnk8fbeQ7R2pJUMRCQ2lAzyWBfcPFZPIhGJCyWDPOp3HKAyadROGlvuUEREBoWSQR7rdh6gdtJYRlTon0dE4kFnu27cnXU79ut+gYjEipJBN80H29nT0qH7BSISK0oG3Rx58ljvJBKRGFEy6GbdzmwyOFdXBiISI0oG3by2eR8zTh6tMQxEJFaUDHI0vdvKyxua+ciFU8sdiojIoFIyyPHE8m0A3HzZ9CJziohES9hhL28ys3ozy5hZXZ76GjNrMbMv5ZTNN7O3zKzRzO4Js/2BlEpneGL5Nq48ayLVelOpiMRM2CuDtcCNwMsF6r8HvNA1YWZJ4EfAh4FZwK1mNitkDAPipYbd7D7Yzm1XnFbuUEREBl3YMZAbAMyOf82zmV0PbAYO5RRfDjS6+6ZgnseB64B1YeIYCI+9uoUpJ1Zx5dkTyx2KiMigK8k9AzMbA3wV+Ea3qmnAtpzppqCs0HoWmNkKM1vR3Nw88IEGtu5t5Q8b9nDzZdOpSOo2iojET9Ezn5ktNbO1eT7X9bDY14Hvu3tLmODcfaG717l73cSJpfuL/eevbSWZMG65rKZk2xARGcqKNhO5+7x+rPcK4ONm9l1gPJAxs8PASiC3q041sL0f6x8we1raeXTZFj4061Qmn1hVzlBERMom1D2DQtz9/V3fzezrQIu7/9DMKoBaM5tJNgncAnyyFDH01g+WbqAtleZL155dzjBERMoqbNfSG8ysCZgLPG9mS3qa3907gS8AS4AG4JfuXh8mhjA2Nrfw89e28snLazhj4phyhSEiUnZhexMtAhYVmefr3aYXA4vDbHegfPuF9YyqTHL3vNpyhyIiUlax7Trz6qa9/GbdO3z2g6dzypiR5Q5HRKSsYpsM/mHJW0weV8Ud7zu93KGIiJRdLJNB/Y79rNjyLp95/0xGjUiWOxwRkbKLZTJ47NWtjKxI8PFLq8sdiojIkBC7ZNDS3smzr2/nLy6YyvjRI8odjojIkBC7ZPDM69s51JHmP87R08YiIl1ilQzcncde3cqsKeO4aPr4cocjIjJkxCoZrNr6Hg07D3DbnJq8b1oVEYmrWCWDx17dwpiRFVx3UcEXpYqIxFKsksGfGvdy9bmTGDOyJK9kEhEZtmKVDA51dDJBPYhERI4Tq2TQ1pHWQ2YiInnEJhl0dGbozDijK5UMRES6i00yaEulAXRlICKSR3ySQYeSgYhIIbFJBq0dnQCMVjIQETlO2JHObjKzejPLmFldTvkMM2szs9XB519y6i41szVm1mhm99kgPf11pJmoUt1KRUS6C3tlsBa4EXg5T91Gd78o+Hw2p/x+4E6gNvjMDxlDr6iZSESksFDJwN0b3P2t3s5vZlOAce6+zN0deAS4PkwMvdUaJAM1E4mIHK+U9wxmmtnrZvZ7M3t/UDYNaMqZpykoK7mjzURKBiIi3RVtQDezpcDkPFX3uvuzBRbbCdS4+14zuxR4xsxm9zU4M1sALACoqQn3ymk1E4mIFFY0Gbj7vL6u1N3bgfbg+0oz2wicBWwHcocXqw7KCq1nIbAQoK6uzvsaRy41E4mIFFaSZiIzm2hmyeD76WRvFG9y953AATObE/Qiuh0odHUxoLqaiUarN5GIyHHCdi29wcyagLnA82a2JKj6APCmma0GngQ+6+77grq7gAeBRmAj8EKYGHqrLXjOQM1EIiLHC/VnsrsvAhblKX8KeKrAMiuA88Jstz9aO9IkE0ZlUoPaiIh0F6MnkNOMrkxqhDMRkTxikwwOp/T6ahGRQmKTDFo1loGISEHxSgZ64ExEJK/YJIPDqbSeMRARKSA2yaC1o1PNRCIiBcQoGaT1+moRkQJikwzUTCQiUlhskoFuIIuIFBabZNCmrqUiIgXFJxmomUhEpKBYJIOOzgydGVcyEBEpIBbJoGtgmyrdMxARySseyaBrLIMR6loqIpJPLJJBazCWgZqJRETyi0kyUDORiEhPYpEMjjYTKRmIiOQTdtjLm8ys3swyZlbXre4CM/vXoH6NmVUF5ZcG041mdp8NwmgzXTeQlQxERPILe2WwFrgReDm30MwqgEfJjn08G7gSSAXV9wN3ArXBZ37IGIpSM5GISM9CJQN3b3D3t/JUfQh4093fCObb6+5pM5sCjHP3Ze7uwCPA9WFi6I22lG4gi4j0pFT3DM4C3MyWmNkqM/tKUD4NaMqZrykoy8vMFpjZCjNb0dzc3O9g2joygLqWiogUUvTsaGZLgcl5qu5192d7WO/7gMuAVuAlM1sJ7O9LcO6+EFgIUFdX531ZNldX11K9qE5EJL+iycDd5/VjvU3Ay+6+B8DMFgOXkL2PUJ0zXzWwvR/r75OuG8h6UZ2ISH6laiZaApxvZqODm8kfBNa5+07ggJnNCXoR3Q4UuroYMG2pNBUJY0RFLHrSioj0WdiupTeYWRMwF3jezJYAuPu7wPeA5cBqYJW7Px8sdhfwINAIbAReCBNDb7Tq9dUiIj0KdUfV3RcBiwrUPUq2Wah7+QrgvDDb7as2DWwjItKjWLSbaCwDEZGexSIZZJuJ1K1URKSQWCSDtlQnoypjsasiIv0SizNkW0daD5yJiPQgFslAvYlERHoWi2TQllJvIhGRnsQiGbR2qDeRiEhPYpEMDquZSESkR5FPBu5Oq5qJRER6FPlk0JHOkM64molERHoQ+WRwOBjLQA+diYgUFvlk0KpRzkREiop+Mugay0D3DERECop8MtDANiIixUU/GaSyyUDNRCIihUU+GaiZSESkuLAjnd1kZvVmljGzupzy28xsdc4nY2YXBXWXmtkaM2s0s/uC4S9LRs1EIiLFhb0yWAvcCLycW+juj7n7Re5+EfCfgM3uvjqovh+4E6gNPvNDxtCjtiO9idS1VESkkFDJwN0b3P2tIrPdCjwOYGZTgHHuvszdHXgEuD5MDMWomUhEpLjB+HP5ZuC64Ps0oCmnrikoKxk1E4mIFFc0GZjZUmBynqp73f3ZIsteAbS6+9r+BGdmC4AFADU1Nf1ZxZFkoN5EIiKFFU0G7j4vxPpvAX6RM70dqM6Zrg7KCm17IbAQoK6uzvsTQGsqTUXCqExGvuOUiEi/lewMaWYJ4BME9wsA3H0ncMDM5gS9iG4Hery6CKtNr68WESkqbNfSG8ysCZgLPG9mS3KqPwBsc/dN3Ra7C3gQaAQ2Ai+EiaGYNg1sIyJSVKgbyO6+CFhUoO53wJw85SuA88Jsty9aU2l1KxURKSLyDeltHZ1UqVupiEiPop8MUmomEhEpJvLJoFX3DEREiop8MmjrSKuZSESkiOgnAzUTiYgUFflkoGYiEZHiIp8M1EwkIlJc5JPBvHMncUH1ieUOQ0RkSIv801j/eMvF5Q5BRGTIi/yVgYiIFKdkICIiSgYiIqJkICIiKBmIiAhKBiIigpKBiIigZCAiIoC592uc+UFnZs3Aln4ufgqwZwDDGQ7iuM8Qz/2O4z5DPPe7r/t8mrtP7M2MwyYZhGFmK9y9rtxxDKY47jPEc7/juM8Qz/0u5T6rmUhERJQMREQkPslgYbkDKIM47jPEc7/juM8Qz/0u2T7H4p6BiIj0LC5XBiIi0oNIJwMzm29mb5lZo5ndU+54SsXMppvZb81snZnVm9ndQflJZvYbM9sQ/JxQ7lgHmpklzex1M/t1MD3TzF4NjvkTZjai3DEONDMbb2ZPmtl6M2sws7lRP9Zm9tfB/+21ZvYLM6uK4rE2s4fNbLeZrc0py3tsLeu+YP/fNLNLwmw7ssnAzJLAj4APA7OAW81sVnmjKplO4G/dfRYwB/h8sK/3AC+5ey3wUjAdNXcDDTnT3wG+7+5nAu8Cd5QlqtL6AfCiu58DXEh2/yN7rM1sGvBXQJ27nwckgVuI5rH+CTC/W1mhY/thoDb4LADuD7PhyCYD4HKg0d03uXsH8DhwXZljKgl33+nuq4LvB8meHKaR3d+fBrP9FLi+PBGWhplVA38OPBhMG3AV8GQwSxT3+UTgA8BDAO7e4e7vEfFjTXZUxlFmVgGMBnYSwWPt7i8D+7oVFzq21wGPeNYyYLyZTenvtqOcDKYB23Kmm4KySDOzGcDFwKvAqe6+M6jaBZxaprBK5R+BrwCZYPpk4D137wymo3jMZwLNwI+D5rEHzewEInys3X078L+ArWSTwH5gJdE/1l0KHdsBPcdFORnEjpmNAZ4CvujuB3LrPNttLDJdx8zsL4Dd7r6y3LEMsgrgEuB+d78YOES3JqEIHusJZP8KnglMBU7g+KaUWCjlsY1yMtgOTM+Zrg7KIsnMKskmgsfc/emg+J2uy8bg5+5yxVcC/x74qJm9TbYJ8Cqybenjg6YEiOYxbwKa3P3VYPpJsskhysd6HrDZ3ZvdPQU8Tfb4R/1Ydyl0bAf0HBflZLAcqA16HIwge8PpuTLHVBJBW/lDQIO7fy+n6jngU8H3TwHPDnZspeLuX3P3anefQfbY/j93vw34LfDxYLZI7TOAu+8CtpnZ2UHR1cA6InysyTYPzTGz0cH/9a59jvSxzlHo2D4H3B70KpoD7M9pTuo7d4/sB/gz4N+AjcC95Y6nhPv5PrKXjm8Cq4PPn5FtQ38J2AAsBU4qd6wl2v8rgV8H308HXgMagV8BI8sdXwn29yJgRXC8nwEmRP1YA98A1gNrgZ8BI6N4rIFfkL0vkiJ7FXhHoWMLGNkekxuBNWR7W/V723oCWUREIt1MJCIivaRkICIiSgYiIqJkICIiKBmIiAhKBiIigpKBiIigZCAiIsD/B8m2VNr5YA/vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11faa29b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STATE_COUNT = 8\n",
    "\n",
    "hmm = HMM.from_random_parameters(S=STATE_COUNT)\n",
    "y,x = hmm.generate_sequence(100)\n",
    "\n",
    "y2,x2 = hmm.generate_sequence(100)\n",
    "\n",
    "print('original A')\n",
    "print(hmm.A)\n",
    "print('original B_avg')\n",
    "print(hmm.B_avg)\n",
    "print('original B_std')\n",
    "print(hmm.B_sd)\n",
    "\n",
    "print('original ll for the first series')\n",
    "print(hmm.get_ll(y))\n",
    "print('original ll for the second series')\n",
    "print(hmm.get_ll(y2))\n",
    "\n",
    "\n",
    "#reinitialize hmm\n",
    "hmm = HMM.from_random_parameters(S=STATE_COUNT)\n",
    "\n",
    "\n",
    "print('original ll for the second series for random hmm')\n",
    "print(hmm.get_ll(y2))\n",
    "\n",
    "LL = hmm.train_EM(y,EPOCH = 100)\n",
    "\n",
    "\n",
    "print('original ll for the second series for trained hmm')\n",
    "print(hmm.get_ll(y2))\n",
    "\n",
    "print('learned A')\n",
    "print(hmm.A)\n",
    "print('learned B_avg')\n",
    "print(hmm.B_avg)\n",
    "print('learned B_std')\n",
    "print(hmm.B_sd)\n",
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakansirin/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "l = [float('-Inf'),float('-Inf')]\n",
    "l_star = np.max(l, keepdims=True)\n",
    "idx = np.where(l_star == float('-inf'))\n",
    "l_star[idx] = -1e32\n",
    "ret = l_star + np.log(np.sum(np.exp(l - l_star),keepdims=True)) \n",
    "print(ret)\n",
    "\n",
    "print(float('-inf')-float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
